{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10139822,"sourceType":"datasetVersion","datasetId":6258183}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:41:06.739321Z","iopub.execute_input":"2024-12-08T17:41:06.739615Z","iopub.status.idle":"2024-12-08T17:41:07.855727Z","shell.execute_reply.started":"2024-12-08T17:41:06.739587Z","shell.execute_reply":"2024-12-08T17:41:07.854885Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sentimentanalysis/task3/train3.csv\n/kaggle/input/sentimentanalysis/task3/test3.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Kaggle optimizations\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nos.environ['TORCH_DISTRIBUTED_DEBUG'] = 'INFO'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:41:07.857414Z","iopub.execute_input":"2024-12-08T17:41:07.857891Z","iopub.status.idle":"2024-12-08T17:41:07.864435Z","shell.execute_reply.started":"2024-12-08T17:41:07.857850Z","shell.execute_reply":"2024-12-08T17:41:07.863568Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Check GPU availability and type\nimport torch\nprint(\"CUDA Available:\", torch.cuda.is_available())\nprint(\"GPU Device:\", torch.cuda.get_device_name(0))\nprint(\"Number of GPUs:\", torch.cuda.device_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:41:07.865704Z","iopub.execute_input":"2024-12-08T17:41:07.865978Z","iopub.status.idle":"2024-12-08T17:41:11.139324Z","shell.execute_reply.started":"2024-12-08T17:41:07.865954Z","shell.execute_reply":"2024-12-08T17:41:11.138489Z"}},"outputs":[{"name":"stdout","text":"CUDA Available: True\nGPU Device: Tesla T4\nNumber of GPUs: 2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport torch.nn.functional as F\nfrom transformers import AdamW\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:41:19.085855Z","iopub.execute_input":"2024-12-08T17:41:19.086527Z","iopub.status.idle":"2024-12-08T17:41:32.712616Z","shell.execute_reply.started":"2024-12-08T17:41:19.086492Z","shell.execute_reply":"2024-12-08T17:41:32.711691Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:41:35.056175Z","iopub.execute_input":"2024-12-08T17:41:35.057394Z","iopub.status.idle":"2024-12-08T17:41:35.068041Z","shell.execute_reply.started":"2024-12-08T17:41:35.057321Z","shell.execute_reply":"2024-12-08T17:41:35.067140Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def load_data(filepath):\n    df = pd.read_csv(filepath)\n    # Remove any NaN values\n    df = df.dropna()\n    # Map sentiment labels to appropriate format (-1 -> 0, 0 -> 1, 1 -> 2)\n    df['category'] = df['category'].map({-1: 0, 0: 1, 1: 2})\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:42:03.223209Z","iopub.execute_input":"2024-12-08T17:42:03.223906Z","iopub.status.idle":"2024-12-08T17:42:03.228202Z","shell.execute_reply.started":"2024-12-08T17:42:03.223867Z","shell.execute_reply":"2024-12-08T17:42:03.227334Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Custom Dataset class for our Twitter data\nclass TwitterDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        # Tokenize the text\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:45:18.288485Z","iopub.execute_input":"2024-12-08T17:45:18.289364Z","iopub.status.idle":"2024-12-08T17:45:18.298841Z","shell.execute_reply.started":"2024-12-08T17:45:18.289298Z","shell.execute_reply":"2024-12-08T17:45:18.297863Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Training function\ndef train_epoch(model, data_loader, optimizer, device):\n    model.train()\n    total_loss = 0\n    \n    progress_bar = tqdm(data_loader, desc='Training')\n    for batch in progress_bar:\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        \n        loss = outputs.loss\n        total_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n        progress_bar.set_postfix({'loss': loss.item()})\n    \n    return total_loss / len(data_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:45:19.271568Z","iopub.execute_input":"2024-12-08T17:45:19.272014Z","iopub.status.idle":"2024-12-08T17:45:19.279900Z","shell.execute_reply.started":"2024-12-08T17:45:19.271972Z","shell.execute_reply":"2024-12-08T17:45:19.278938Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc='Evaluating'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            \n            preds = torch.argmax(outputs.logits, dim=1)\n            predictions.extend(preds.cpu().numpy())\n            actual_labels.extend(labels.cpu().numpy())\n    \n    return predictions, actual_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:45:20.318576Z","iopub.execute_input":"2024-12-08T17:45:20.319377Z","iopub.status.idle":"2024-12-08T17:45:20.326999Z","shell.execute_reply.started":"2024-12-08T17:45:20.319311Z","shell.execute_reply":"2024-12-08T17:45:20.325847Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Main execution\ndef main():\n    # Load the data\n    df = load_data('/kaggle/input/sentimentanalysis/task3/train3.csv')\n    \n    # Initialize tokenizer\n    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n    \n    # Split the data\n    train_texts, val_texts, train_labels, val_labels = train_test_split(\n        df['Text'].values,\n        df['category'].values,\n        test_size=0.1,\n        random_state=42,\n        stratify=df['category'].values\n    )\n    \n    # Create datasets\n    train_dataset = TwitterDataset(train_texts, train_labels, tokenizer)\n    val_dataset = TwitterDataset(val_texts, val_labels, tokenizer)\n    \n    # Create data loaders\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32)\n    \n    # Initialize model\n    model = DistilBertForSequenceClassification.from_pretrained(\n        'distilbert-base-uncased',\n        num_labels=3\n    ).to(device)\n    \n    # Calculate class weights to handle imbalance\n    class_counts = df['category'].value_counts().sort_index()\n    class_weights = torch.tensor(\n        [1.0 / (count / len(df)) for count in class_counts],\n        dtype=torch.float\n    ).to(device)\n    \n    # Initialize optimizer with weight decay\n    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n    \n    # Training loop\n    num_epochs = 3\n    best_val_f1 = 0\n    \n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n        \n        # Train\n        train_loss = train_epoch(model, train_loader, optimizer, device)\n        print(f\"Average training loss: {train_loss:.4f}\")\n        \n        # Evaluate\n        val_preds, val_labels = evaluate(model, val_loader, device)\n        \n        # Print metrics\n        print(\"\\nValidation Results:\")\n        print(classification_report(val_labels, val_preds))\n        \n        # Save best model\n        val_f1 = classification_report(val_labels, val_preds, output_dict=True)['macro avg']['f1-score']\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            torch.save(model.state_dict(), 'best_model.pt')\n            print(\"New best model saved!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:45:21.170687Z","iopub.execute_input":"2024-12-08T17:45:21.171311Z","iopub.status.idle":"2024-12-08T19:16:05.378295Z","shell.execute_reply.started":"2024-12-08T17:45:21.171276Z","shell.execute_reply":"2024-12-08T19:16:05.377471Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 8679/8679 [29:11<00:00,  4.96it/s, loss=0.00688]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.1953\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 483/483 [00:59<00:00,  8.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Results:\n              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96      3373\n           1       0.99      0.98      0.98      5232\n           2       0.97      0.98      0.98      6823\n\n    accuracy                           0.97     15428\n   macro avg       0.97      0.97      0.97     15428\nweighted avg       0.97      0.97      0.97     15428\n\nNew best model saved!\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 8679/8679 [29:16<00:00,  4.94it/s, loss=0.145]   \n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.0679\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 483/483 [00:58<00:00,  8.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Results:\n              precision    recall  f1-score   support\n\n           0       0.95      0.98      0.97      3373\n           1       0.99      0.98      0.99      5232\n           2       0.99      0.98      0.98      6823\n\n    accuracy                           0.98     15428\n   macro avg       0.98      0.98      0.98     15428\nweighted avg       0.98      0.98      0.98     15428\n\nNew best model saved!\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 8679/8679 [29:16<00:00,  4.94it/s, loss=0.00178] \n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.0452\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 483/483 [00:58<00:00,  8.22it/s]","output_type":"stream"},{"name":"stdout","text":"\nValidation Results:\n              precision    recall  f1-score   support\n\n           0       0.92      0.99      0.95      3373\n           1       0.99      0.98      0.99      5232\n           2       0.99      0.96      0.98      6823\n\n    accuracy                           0.97     15428\n   macro avg       0.97      0.98      0.97     15428\nweighted avg       0.98      0.97      0.97     15428\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}